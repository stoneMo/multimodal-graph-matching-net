<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<!-- ======================================================================= -->
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<style type="text/css">
  body {
    /* font-family: "Titillium Web","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; */
    font-family: "Times New Roman", Serif;
    font-weight:300;
    font-size:20px;
    margin-left: auto;
    margin-right: auto;
    width: 1100px;
  }

  h1 {
    font-weight:300;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }

  #authors td {
    padding-bottom:5px;
    padding-top:30px;
  }
</style>
<!-- ======================================================================= -->

<!-- Start : Google Analytics Code -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-64069893-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-64069893-4');
</script>
<!-- End : Google Analytics Code -->

<script type="text/javascript" src="resources/hidebib.js"></script>
<!-- <script type="text/javascript" src="resources/LaTeXMathML.js"></script> -->
<!-- End : MathLatex Package -->
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link rel="icon" type="image/png" href="resources/seal_icon.png">
  <title>Referring 3D Instances via multimodal graph matching</title>
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="canonical" href="https://pathak22.github.io/modular-assemblies/" />
  <meta name="referrer" content="no-referrer-when-downgrade" />

  <meta property="og:site_name" content="Self-Assembling Morphologies" />
  <meta property="og:type" content="video.other" />
  <meta property="og:title" content="Learning to Control Self-Assembling Morphologies: A Study of Generalization via Modularity" />
  <meta property="og:description" content="Pathak, Lu, Darrell, Isola, Efros. Learning to Control Self-Assembling Morphologies: A Study of Generalization via Modularity. 2019." />
  <meta property="og:url" content="https://pathak22.github.io/modular-assemblies/" />
  <meta property="og:image" content="https://pathak22.github.io/modular-assemblies/resources/teaser.jpg" />
  <meta property="og:video" content="https://www.youtube.com/v/ngCIB-IWD8E" />

  <meta property="article:publisher" content="http://people.eecs.berkeley.edu/~pathak/" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Learning to Control Self-Assembling Morphologies: A Study of Generalization via Modularity" />
  <meta name="twitter:description" content="Pathak, Lu, Darrell, Isola, Efros. Learning to Control Self-Assembling Morphologies: A Study of Generalization via Modularity. 2019." />
  <meta name="twitter:url" content="https://pathak22.github.io/modular-assemblies/" />
  <meta name="twitter:image" content="https://pathak22.github.io/modular-assemblies/resources/teaser.jpg" />
  <meta name="twitter:label1" content="Written by" />
  <meta name="twitter:data1" content="Deepak Pathak" />
  <meta name="twitter:label2" content="Filed under" />
  <meta name="twitter:data2" content="" />
  <meta name="twitter:site" content="@pathak" />
  <meta property="og:image:width" content="1600" />
  <meta property="og:image:height" content="900" />

  <script src="https://www.youtube.com/iframe_api"></script>
  <meta name="twitter:card" content="player" />
  <meta name="twitter:image" content="https://pathak22.github.io/modular-assemblies/resources/teaser.jpg" />
  <meta name="twitter:player" content="https://www.youtube.com/embed/ngCIB-IWD8E?rel=0&showinfo=0" />
  <meta name="twitter:player:width" content="640" />
  <meta name="twitter:player:height" content="360" />
</head>

<body>
      <br>
      <center><span style="font-size:44px;font-weight:bold;">Referring 3D Instances via Multimodal Graph Matching</center><br/>
      <table align=center width=800px>
      <tr>
        <td align=center width=150px>
        <center><span style="font-size:22px"><a href="https://www.ri.cmu.edu/ri-people/jianchun-chen/" target="_blank">Jianchun Chen *</a></span></center></td>
        <td align=center width=150px>
        <center><span style="font-size:22px"><a href="https://stonemo.github.io/" target="_blank">Shentong Mo *</a></span></center></td>
        <!-- <td align=center width=150px>
        <center><span style="font-size:22px"><a href="https://people.eecs.berkeley.edu/~trevor/" target="_blank">Trevor Darrell</a></span></center></td>
        <td align=center width=150px>
        <center><span style="font-size:22px"><a href="https://www.eecs.mit.edu/people/faculty/phillip-isola/" target="_blank">Phillip Isola</a></span></center></td>
        <td align=center width=150px>
        <center><span style="font-size:22px"><a href="https://people.eecs.berkeley.edu/~efros/" target="_blank">Alexei A. Efros</a></span></center></td> -->
      <tr/>
      <tr>
        <td align=center width=200px>
        <center><span style="font-size:20px">Carnegie Mellon University</span></center></td>
        <td align=center width=200px>
        <center><span style="font-size:20px">Carnegie Mellon University</span></center></td>
        <!-- <td align=center width=200px>
        <center><span style="font-size:20px">UC Berkeley</span></center></td>
        <td align=center width=200px>
        <center><span style="font-size:20px">MIT</span></center></td>
        <td align=center width=200px>
        <center><span style="font-size:20px">UC Berkeley</span></center></td> -->
      <tr/>
      </table>
      <table align=center width=600px style="padding-top:0px;padding-bottom:20px">
          <tr>
            <td align=center width=600px><center><span style="font-size:20px">* equal contribution</span></center></td>
          <tr/>
      </table>
      <table align=center width=700px>
          <tr>
            <td align=center width=700px><center><span style="font-size:22px">Course Project at <a href="https://visual-learning.cs.cmu.edu/">16824: Visual Learning and Recognition, 2021 Spring</a></span></center></td>
          <tr/>
          <!-- <tr>
            <td align=center width=700px><center><span style="font-size:22px">Winner of the <a href="https://virtualcreatures.github.io/">Virtual Creatures Competition at GECCO 2019</a></span></center></td>
          <tr/> -->
      </table><br/>
      <table align=center width=700px>
          <tr>
            <!-- <td align=center width=100px><center><span style="font-size:28px"><a href="resources/assemblies.pdf">[Report]</a></span></center></td> -->
            <td align=center width=100px><center><span style="font-size:28px"><a href="resources/slides.pdf">[Slides]</a></span></center></td>
            <!-- <td align=center width=100px><center><span style="font-size:28px"><a href="resources/poster.pdf">[Poster]</a></span></center></td> -->
            <td align=center width=100px><center><span style="font-size:28px"><a href='https://github.com/pathak22/modular-assemblies/'>[GitHub Code]</a></span></center></td>
          <tr/>
      </table><br/>

<!--       <center><h2>Project Video</h2></center> -->
      <table align=center width=300px>
      <tr><td align=center width=300px>
      <iframe width="768" height="432" src="https://www.youtube.com/embed/ngCIB-IWD8E?rel=0" frameborder="0" allowfullscreen></iframe>
      </td></tr>
      </table>
      <br>
      
      <center><h1>Introduction</h1></center>
      <div style="width:800px; margin:0 auto; text-align=center">
      <!-- <div class="col col-wrapper"> -->
        3D referring (grounding) is a newly defined vision task aiming at indicating target object describedby nature languages from a 3D scene. While some research have achieved great success in referring2D instances in a image or video context, predicting desired 3D instance is still an open problem,since 3D scene provides more complicated visual information and spatial relation among differentobjects. In addition, there are countless sentences that can describe the position of a 3D object, whichmakes the language harder to understand. However, this task attracts researcher’s attention with richpotential to apply in human-computer interaction, navigation, etc.  

        <!-- <blockquote>$\displaystyle{\hat{N}^l_i = \phi_n(N^l_i); \hat{E}^l_t = \phi_e(E^l_i)}$</blockquote> -->
        <!-- $\\$\alpha + \\$\beta = \\$(\alpha + \beta).$ -->
      </div><br/>

      <div style="width:800px; margin:0 auto; text-align=center">
      <!-- <div class="col col-wrapper"> -->
        To approach this task, previous efforts mainly contain two steps: 1) they first segment 3D instancesand learn instance-level visual representation throughout the scene; 2) then integrate the visual featurewith input language features and determine the instance(s) that best align the feature of input language. This pipeline successfully addresses many simple query sentence, but easily failed when the querysentences describe complex spatial relation between objects (e.g., 'Standing in the middle of the room,looking at the two windows, the one to the right'). One critical issue that accounts is, the structureand relation of language tokens are equally important compared with the vision part, but harderto understand. By treating language as a linear structure, neither max-pooling [1,2] nor attentionmechanism [3] is sufficient to learn spatial relationship in language effectively.      
        \(\alpha\)
        \(\hat{N}^l_i = \phi_n(N^l_i); \hat{E}^l_t = \phi_e(E^l_i)\)
        \[\hat{N}^l_i = \phi_n(N^l_i); \hat{E}^l_t = \phi_e(E^l_i)\]

        <!-- <blockquote>$\displaystyle{\hat{N}^l_i = \phi_n(N^l_i); \hat{E}^l_t = \phi_e(E^l_i)}$</blockquote> -->

        <!-- $\\$\alpha + \\$\beta = \\$(\alpha + \beta).$ -->
      </div><br/>

      <style type="text/css">
        .tg  {border-collapse:collapse;border-spacing:0;}
        .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
          overflow:hidden;padding:10px 5px;word-break:normal;}
        .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
          font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
        .tg .tg-7zrl{text-align:left;vertical-align:bottom}
        </style>
        <table class="center">
        <thead>
          <tr>
            <th class="tg-7zrl">Method  </th>
            <th class="tg-7zrl">Acc@0.25IoU</th>
            <th class="tg-7zrl">Acc@0.5IoU</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td class="tg-7zrl">TGNN</td>
            <td class="tg-7zrl">29.88</td>
            <td class="tg-7zrl">35.71</td>
          </tr>
          <tr>
            <td class="tg-7zrl">IR</td>
            <td class="tg-7zrl">28.93</td>
            <td class="tg-7zrl">35.69</td>
          </tr>
        </tbody>
        </table>

      <center><h1>Introduction</h1></center>
      <div style="width:800px; margin:0 auto; text-align=center">
        This work investigates the joint learning of control and morphology in self-assembling agents. We illustrate our dynamic agents in two environments / tasks: standing up and locomotion. For each of these, we generate several new environment for evaluating zero-shot generalization without any finetuning.
      </div><br/>
      <table align=center width=1000px>
        <p style="margin-top:4px;"></p>
        <tr><td width=1200px>
          <center><a href="resources/teaser.jpg"><img src = "resources/teaser.jpg" height="450px"></img></a><br></center>
        </td></tr>
      </table>
      <br/><hr>

      <center id="sourceCode"><h1>Source Code and Environment</h1></center>
      <div style="width:800px; margin:0 auto; text-align=center">
      We have released the PyTorch based implementation and environment on the github page. Try our code!
      </div>
      <table align=center width=900px>
        <tr>
          <!-- <p style="margin-top:4px;"></p> -->
          <td width=300px align=center>
            <span style="font-size:28px"><a href='https://github.com/pathak22/modular-assemblies/'>[GitHub]</a></span>
          </td>
        </tr>
      </table>
      <br><hr>

      <table align=center width=850px>
        <center><h1>Paper and Bibtex</h1></center>
        <tr>
        <td width=250px align=left>
        <!-- <p style="margin-top:4px;"></p> -->
        <a href="resources/assemblies.pdf"><img style="height:150px" src="resources/thumbnail.jpeg"/></a>
        <center>
        <span style="font-size:20pt"><a href="resources/assemblies.pdf">[Paper]</a>
        <span style="font-size:20pt"><a href="https://arxiv.org/abs/1902.05546v2">[ArXiv]</a>
        <span style="font-size:20pt"><a href="resources/slides.pdf">[Slides]</a></span>
        <span style="font-size:20pt"><a href="resources/poster.pdf">[Poster]</a></span>
        </center>
        </td>
        <td width=50px align=center>
        </td>
        <td width=550px align=left>
        <!-- <p style="margin-top:4px;"></p> -->
        <p style="text-align:left;"><b><span style="font-size:20pt">Citation</span></b><br/><span style="font-size:6px;">&nbsp;<br/></span> <span style="font-size:15pt">Deepak Pathak, Chris Lu, Trevor Darrell, Phillip Isola, Alexei A. Efros. <b>Learning to Control Self-Assembling Morphologies: A Study of Generalization via Modularity<br/></b> In <i>NeurIPS</i> 2019.</span></p>
        <!-- <p style="margin-top:20px;"></p> -->
        <span style="font-size:20pt"><a shape="rect" href="javascript:togglebib('assemblies19_bib')" class="togglebib">[Bibtex]</a></span>
        </td>
        </tr>
        <tr>
        <td width=250px align=left>
        </td>
        <td width=50px align=center>
        </td>
        <td width=550px align=left>
          <div class="paper" id="assemblies19_bib">
<pre xml:space="preserve">
@inproceedings{pathak19assemblies,
  Author = {Pathak, Deepak and
  Lu, Chris and Darrell, Trevor and
  Isola, Phillip and Efros, Alexei A.},
  Title = {Learning to Control Self-
  Assembling Morphologies: A Study of
  Generalization via Modularity},
  Booktitle = {NeurIPS},
  Year = {2019}
}</pre>
          </div>
          </td>
          </tr>
      </table>
    <br><hr>

    <table align=center width=800px>
      <tr><td width=800px><left>
      <center><h1>Acknowledgements</h1></center>
      We would like to thank Igor Mordatch, Chris Atkeson, Abhinav Gupta and the members of BAIR for fruitful discussions and comments. This work was supported in part by Berkeley DeepDrive, and the Valrhona reinforcement learning fellowship. DP is supported by the Facebook graduate fellowship.<br>
      </left></td></tr>
    </table>
  <br><br>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
</body>
</html>
